{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Image Classificaation using SVM is very efficient way of modelling and very rarely used algorithm for image processing and modelling..!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Tips for using SVM for image classification\n",
    "\n",
    "* You should have image data in 2D rather than 4D (as SVM training model accepts dim <=2 so we need to convert the image data to 2D which i'll be showing later on in this notebook).\n",
    "\n",
    "* SVM algorithm is to be used when their is shortage of data in our dataset .\n",
    "\n",
    "* If we have good amount of image data so, we look further for CNN model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Importing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "importing basic Packages..!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "now,we have provided data directory to DATADIR variable and labels of color set to CATEGORIES variable for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../input/colours_classifier'\n",
    "CATEGORIES = ['Green','Red','Blue']\n",
    "IMG_SIZE=100"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Ex. of an sample image is shown below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for category in CATEGORIES:\n",
    "    path=os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img))\n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_array)\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "performing preprocessing steps...::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path=os.path.join(DATADIR, category)\n",
    "        class_num=CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "storing trainig length for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenofimage = len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "for image to be trained we have to convert the image to a array form so,that our model can train on it...!!"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "and X should be of type (training_data_length , -1) because SVM takes 2D input to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for categories, label in training_data:\n",
    "    X.append(categories)\n",
    "    y.append(label)\n",
    "X= np.array(X).reshape(lenofimage,-1)\n",
    "##X = tf.keras.utils.normalize(X, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 30000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**flattening the array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Ex. of flattened array..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07843137, 0.70588235, 0.23529412, ..., 0.07843137, 0.70588235,\n",
       "       0.23529412])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "note : y should be in array form compulsory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Now we are ready with our dependent and independent features, now its time for data modelling\n",
    "\n",
    "applying train_test_split on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**fitting our data in SVM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear',C = 100)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**predicting the X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on unknown data is 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on unknown data is\",accuracy_score(y_test,y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Ahhyeah....accuracy of 100% which is what we wanted..!!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "all the test unseen (X_test) images are classified to their paticular labels"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**fromulating the Classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on unknown data is               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        52\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00       138\n",
      "   macro avg       1.00      1.00      1.00       138\n",
      "weighted avg       1.00      1.00      1.00       138\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Accuracy on unknown data is\",classification_report(y_test,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'original' : y_test,'predicted' : y2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     original  predicted\n",
       "0           2          2\n",
       "1           2          2\n",
       "2           0          0\n",
       "3           2          2\n",
       "4           0          0\n",
       "..        ...        ...\n",
       "133         0          0\n",
       "134         0          0\n",
       "135         2          2\n",
       "136         2          2\n",
       "137         2          2\n",
       "\n",
       "[138 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "we have moslty classified all the images correctly with their labels .doing classification on limited dataset is always a challenging task....but by SVM we have dealed with it succesfully"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "now we will classify the iamge singly to their labels"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Color Identification of Unknown image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAKTElEQVR4nO3dT4ic933H8fcnsnNxAtU2tRGKadJgSk1LlbKIgEtJCQ6OL7IPLdEhqGBQDjEkkENNeqiPJjQJPZSAUouoJXUoJMY6mDZCBEygBK+NastVU7lGbWQJqWEpcU6JrW8P+zhs5F3teP49Q7/vFwwz88yz+3wZ9NbMPLPwS1Uh6f+/94w9gKTlMHapCWOXmjB2qQljl5q4bZkHW8t76iD7lnlIqZXXeYvNupGdHpsp9iQPAH8N7AP+tqqeuNX+B9nH0/zaLIeUdAsP87+7Pjb12/gk+4C/AT4F3AscTXLvtL9P0mLN8pn9MPBqVb1WVT8Hvg0cmc9YkuZtltgPAj/edv/ysO1XJDmeZCPJxiY3ZjicpFnMEvtOJwHe8be3VXWiqtaran3Nk//SaGap7zJw97b7HwSuzDaOpEWZJfbngXuSfDjJe4FPA6fnM5akeZv6q7eqejPJo8A/s/XV28mqemVuk0maq5m+Z6+qZ4Fn5zSLpAXyjJnUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNzLRkc5JLwBvAW8CbVbU+j6Ekzd9MsQ/+uKp+MoffI2mBfBsvNTFr7AV8L8kLSY7vtEOS40k2kmxscmPGw0ma1qxv4++rqitJ7gTOJPn3qnpu+w5VdQI4AfB7ub1mPJ6kKc30yl5VV4br68DTwOF5DCVp/qaOPckdSd7/9m3gk8D5eQ0mab5meRt/F/B0krd/zz9U1T/NZSpJczd17FX1GvD7c5xF0gL51ZvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtN7Bl7kpNJric5v23bWpIzSS4O1/sXO6akWU3yyv5N4IGbtj0GnK2qe4Czw31JK2zP2KvqOWDzps1HgFPD7VPAQ3OeS9KcTfuZ/a6qugowXN+5245JjifZSLKxyY0pDydpVgs/QVdVJ6pqvarW1zwfKI1m2vquJTkAMFxfn99IkhZh2thPA8eG28eAZ+YzjqRFmeSrt6eAfwF+O8nlJI8ATwD3J7kI3D/cl7TCbttrh6o6ustDn5jzLJIWyDNmUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNTHJ+uwnk1xPcn7btseTvJ7k3HB5cLFjSprVJK/s3wQe2GH716rq0HB5dr5jSZq3PWOvqueAzSXMImmBZvnM/miSl4a3+ft32ynJ8SQbSTY2uTHD4STNYtrYvw58BDgEXAW+stuOVXWiqtaran3N84HSaKaqr6quVdVbVXUD+AZweL5jSZq3qWJPcmDb3YeB87vtK2k13LbXDkmeAj4OfCDJZeAvgY8nOQQUcAn47AJnlDQHe8ZeVUd32PzkAmaRtECeMZOaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqmJPWNPcneS7ye5kOSVJJ8ftq8lOZPk4nC9f/HjSprWJK/sbwJfrKrfAT4GfC7JvcBjwNmqugc4O9yXtKL2jL2qrlbVi8PtN4ALwEHgCHBq2O0U8NCihpQ0u3f1mT3Jh4CPAj8E7qqqq7D1HwJw5y4/czzJRpKNTW7MNq2kqU0ce5L3Ad8BvlBVP53056rqRFWtV9X6mucDpdFMVF+S29kK/VtV9d1h87UkB4bHDwDXFzOipHmY5Gx8gCeBC1X11W0PnQaODbePAc/MfzxJ83LbBPvcB3wGeDnJuWHbl4AngH9M8gjw38CfLGZESfOwZ+xV9QMguzz8ifmOI2lRPGMmNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41Mcn67Hcn+X6SC0leSfL5YfvjSV5Pcm64PLj4cSVNa5L12d8EvlhVLyZ5P/BCkjPDY1+rqr9a3HiS5mWS9dmvAleH228kuQAcXPRgkubrXX1mT/Ih4KPAD4dNjyZ5KcnJJPt3+ZnjSTaSbGxyY6ZhJU1v4tiTvA/4DvCFqvop8HXgI8Ahtl75v7LTz1XViapar6r1Nc8HSqOZqL4kt7MV+req6rsAVXWtqt6qqhvAN4DDixtT0qwmORsf4EngQlV9ddv2A9t2exg4P//xJM3LJGfj7wM+A7yc5Nyw7UvA0SSHgAIuAZ9dyISS5mKSs/E/ALLDQ8/OfxxJi+IZM6kJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaSFUt72DJ/wD/tW3TB4CfLG2Ad2dVZ1vVucDZpjXP2X6zqn5jpweWGvs7Dp5sVNX6aAPcwqrOtqpzgbNNa1mz+TZeasLYpSbGjv3EyMe/lVWdbVXnAmeb1lJmG/Uzu6TlGfuVXdKSGLvUxCixJ3kgyY+SvJrksTFm2E2SS0leHpah3hh5lpNJric5v23bWpIzSS4O1zuusTfSbCuxjPctlhkf9bkbe/nzpX9mT7IP+A/gfuAy8DxwtKr+bamD7CLJJWC9qkb/A4wkfwT8DPi7qvrdYduXgc2qemL4j3J/Vf35isz2OPCzsZfxHlYrOrB9mXHgIeDPGPG5u8Vcf8oSnrcxXtkPA69W1WtV9XPg28CREeZYeVX1HLB50+YjwKnh9im2/rEs3S6zrYSqulpVLw633wDeXmZ81OfuFnMtxRixHwR+vO3+ZVZrvfcCvpfkhSTHxx5mB3dV1VXY+scD3DnyPDfbcxnvZbppmfGVee6mWf58VmPEvtNSUqv0/d99VfUHwKeAzw1vVzWZiZbxXpYdlhlfCdMufz6rMWK/DNy97f4HgSsjzLGjqroyXF8Hnmb1lqK+9vYKusP19ZHn+aVVWsZ7p2XGWYHnbszlz8eI/XngniQfTvJe4NPA6RHmeIckdwwnTkhyB/BJVm8p6tPAseH2MeCZEWf5FauyjPduy4wz8nM3+vLnVbX0C/AgW2fk/xP4izFm2GWu3wL+dbi8MvZswFNsva37BVvviB4Bfh04C1wcrtdWaLa/B14GXmIrrAMjzfaHbH00fAk4N1weHPu5u8VcS3ne/HNZqQn/gk5qwtilJoxdasLYpSaMXWrC2KUmjF1q4v8Aglg7eYu1ukoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('../input/colours_classifier/test/3456.jpg')\n",
    "RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(RGB_img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "**Performing preprossing steps..!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array=cv2.resize(img,(IMG_SIZE,IMG_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(new_array).reshape(1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3 = svc.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "({0 : Green , 1 : Red , 2 : Blue})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Ahhyeah we have predicted to it specific label i.e Red "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "let's try some more images...!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('../input/colours_classifier/test/121.png')\n",
    "RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(RGB_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "img = np.array(new_array).reshape(1,-1)\n",
    "img = img/255.0\n",
    "y3 = svc.predict(img)\n",
    "y3"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "({0 : Green , 1 : Red , 2 : Blue})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('../input/colours_classifier/test/159.png')\n",
    "RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(RGB_img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array=cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "img = np.array(new_array).reshape(1,-1)\n",
    "img = img/255.0\n",
    "y3 = svc.predict(img)\n",
    "y3"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "({0 : Green , 1 : Red , 2 : Blue})"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Well,we have succesfully tested image to their particular labels"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Hence,we have classified image to their particular section...!! *Happy Coding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
